{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "56Kw-BSzqEkf",
        "tIVUmZc5qNen",
        "hiKlc3JIXHKA",
        "YLcDHGHgY83m",
        "dkhvEM4DaQdi",
        "fkKIJcGuaiUG",
        "JXXWViJga7LS",
        "BQRp9gJlaDM2",
        "L4rPtR2taLA-",
        "P_C2MwpZabXe",
        "npSGpBmYbucf",
        "lyzURZaRb1MW",
        "7AzI50AdcgH4",
        "nqX4F5g17fBk",
        "w4AGNKFgDgbu",
        "ZAhXrMruGtzO",
        "LbTlG_3iGwam",
        "fW-Tr6XMGzh2",
        "zAT88zCaG06f",
        "8h8xR4m1G6K2",
        "wSddSsNUMha3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrijr009/leaves-classification/blob/main/leaves_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VC - Classificação de Folhas\n",
        "\n",
        "Equipe: Adriano Junior, Anthony Davi e Cássio de Castro."
      ],
      "metadata": {
        "id": "kVBmT6bucmmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar o Dataset pela API"
      ],
      "metadata": {
        "id": "sqmIzz03nHye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fazer o import do .zip pelo Kagglehub"
      ],
      "metadata": {
        "id": "56Kw-BSzqEkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"gauravneupane/flavia-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "Fu_LVi1QnLJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Printar as imagens ( Só pra testar)"
      ],
      "metadata": {
        "id": "tIVUmZc5qNen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "\n",
        "folder = \"/root/.cache/kagglehub/datasets/gauravneupane/flavia-dataset/versions/1/Leaves\"\n",
        "all_files = sorted(os.listdir(folder))[:1907] # Seus 1907 arquivos\n",
        "\n",
        "# Configuração\n",
        "batch_size = 20 # Imagens por figura (4x5)\n",
        "total_batches = math.ceil(len(all_files) / batch_size)\n",
        "\n",
        "print(f\"Gerando {total_batches} grupos de imagens. Isso pode demorar um pouco...\")\n",
        "\n",
        "# Loop pelos lotes (chunks)\n",
        "for batch_idx in range(total_batches):\n",
        "    start = batch_idx * batch_size\n",
        "    end = start + batch_size\n",
        "    batch_files = all_files[start:end]\n",
        "\n",
        "    # Cria uma NOVA figura para cada lote de 20\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    plt.suptitle(f\"Lote {batch_idx + 1} de {total_batches}\", fontsize=16)\n",
        "\n",
        "    for i, fname in enumerate(batch_files):\n",
        "        img_path = os.path.join(folder, fname)\n",
        "        try:\n",
        "            img = imread(img_path)\n",
        "\n",
        "            # Subplot reinicia a contagem para cada figura (1 a 20)\n",
        "            plt.subplot(4, 5, i+1)\n",
        "            plt.imshow(img)\n",
        "            plt.title(fname, fontsize=8)\n",
        "            plt.axis(\"off\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show() # Mostra este lote e libera memória para o próximo\n",
        "\n",
        "    # Dica: Se quiser parar no meio para não gerar centenas de imagens,\n",
        "    # descomente as linhas abaixo:\n",
        "    # if batch_idx == 2:\n",
        "    #     print(\"Parando demonstração para economizar tempo.\")\n",
        "    #     break"
      ],
      "metadata": {
        "id": "XM9u8laTntbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento, Segmentação e Extração de Descritores"
      ],
      "metadata": {
        "id": "hiKlc3JIXHKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import das imagens"
      ],
      "metadata": {
        "id": "YLcDHGHgY83m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Caminho do dataset\n",
        "path = \"/root/.cache/kagglehub/datasets/gauravneupane/flavia-dataset/versions/1/Leaves\""
      ],
      "metadata": {
        "id": "o-qEtWmRXKfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de segmentação da imagem"
      ],
      "metadata": {
        "id": "dkhvEM4DaQdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processar_folha(caminho_img, nome_arquivo):\n",
        "    # 1. Leitura e Conversão para Tons de Cinza\n",
        "    img = cv2.imread(caminho_img)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    # Conversão direta BGR -> Gray\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 2. Limiarização Automática (Otsu)\n",
        "    # Aplicamos um leve GaussianBlur antes apenas para reduzir ruído de sensor,\n",
        "    # ajudando o Otsu a ser mais estável sem perder a forma.\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # THRESH_BINARY_INV + THRESH_OTSU:\n",
        "    # O OpenCV calcula o limiar ideal automaticamente.\n",
        "    # Usamos INV assumindo fundo claro e folha escura.\n",
        "    val_otsu, binaria = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # 3. Limpeza e Eliminação de Artefatos (Morfologia)\n",
        "    # Operação de \"Fechamento\" (Closing) para fechar pequenos buracos DENTRO da folha\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    binaria = cv2.morphologyEx(binaria, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "\n",
        "    # Operação de \"Abertura\" (Opening) para remover ruídos NO FUNDO (fora da folha)\n",
        "    binaria = cv2.morphologyEx(binaria, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "\n",
        "    # 4. Extração do Contorno Principal\n",
        "    # RETR_EXTERNAL: Pega apenas os contornos externos (ignora buracos internos da folha para cálculo de forma global)\n",
        "    # CHAIN_APPROX_NONE: Guarda TODOS os pontos do contorno (máxima precisão).\n",
        "    # Se quiser economizar memória sem perder muita precisão, use CHAIN_APPROX_SIMPLE.\n",
        "    contornos, _ = cv2.findContours(binaria, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "    if not contornos:\n",
        "        return None\n",
        "\n",
        "    # Seleciona o maior contorno pela área (a folha)\n",
        "    c_folha = max(contornos, key=cv2.contourArea)\n",
        "    area = cv2.contourArea(c_folha)\n",
        "\n",
        "    # Filtro de segurança: ignora se for apenas um ruído que sobrou\n",
        "    if area < 1000:\n",
        "        return None\n",
        "\n",
        "    # --- Extração de Descritores (Conforme Enunciado) ---\n",
        "\n",
        "    # A) Circularidade / Compacidade: C = (4 * pi * A) / P^2\n",
        "    perimetro = cv2.arcLength(c_folha, True) # True indica que o contorno é fechado\n",
        "    if perimetro == 0:\n",
        "        return None\n",
        "\n",
        "    circularidade = (4 * np.pi * area) / (perimetro ** 2)\n",
        "\n",
        "    # B) Excentricidade\n",
        "    # Ajusta uma elipse ao redor do contorno e compara o eixo maior com o menor\n",
        "    if len(c_folha) >= 5: # Necessário pelo menos 5 pontos para fitEllipse\n",
        "        (x, y), (eixo_menor, eixo_maior), angle = cv2.fitEllipse(c_folha)\n",
        "\n",
        "        # Garante que a divisão seja sempre do menor pelo maior\n",
        "        # Nota: fitEllipse pode retornar largura/altura em ordem variada dependendo da rotação\n",
        "        a = max(eixo_menor, eixo_maior) / 2.0\n",
        "        b = min(eixo_menor, eixo_maior) / 2.0\n",
        "\n",
        "        # Fórmula: e = sqrt(1 - (b^2 / a^2))\n",
        "        # Se for um círculo perfeito, b=a, excentricidade = 0. Linha reta = 1.\n",
        "        excentricidade = np.sqrt(1 - (b**2 / a**2))\n",
        "    else:\n",
        "        excentricidade = 0.0\n",
        "\n",
        "    # C) Razão Altura / Largura (Bounding Box Retangular)\n",
        "    x, y, w, h = cv2.boundingRect(c_folha)\n",
        "    razao_hw = float(h) / w if w != 0 else 0\n",
        "\n",
        "    # D) Número de Cantos (Shi-Tomasi)\n",
        "    # Shi-Tomasi (goodFeaturesToTrack) é geralmente mais robusto para *contagem* que o Harris puro\n",
        "    # Máscara da folha para não pegar cantos do fundo\n",
        "    mask_folha = np.zeros_like(gray)\n",
        "    cv2.drawContours(mask_folha, [c_folha], -1, 255, -1)\n",
        "\n",
        "    # Parâmetros: maxCorners=0 (ilimitado), qualityLevel=0.01, minDistance=10 pixels\n",
        "    # minDistance evita detectar vários cantos no mesmo \"bico\" da folha\n",
        "    cantos = cv2.goodFeaturesToTrack(gray, maxCorners=0, qualityLevel=0.01, minDistance=10, mask=mask_folha)\n",
        "\n",
        "    if cantos is not None:\n",
        "        num_cantos = len(cantos)\n",
        "    else:\n",
        "        num_cantos = 0\n",
        "\n",
        "    return {\n",
        "        \"Imagem\": nome_arquivo,\n",
        "        \"Area\": area,\n",
        "        \"Perimetro\": perimetro,\n",
        "        \"Circularidade\": circularidade,\n",
        "        \"Excentricidade\": excentricidade,\n",
        "        \"Num_Cantos\": num_cantos,\n",
        "        \"Razao_Altura_Largura\": razao_hw\n",
        "    }"
      ],
      "metadata": {
        "id": "TirSIoohaUXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processando todo dataset"
      ],
      "metadata": {
        "id": "fkKIJcGuaiUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Execução Serial (Mais segura para RAM com imagens Full-Res) ---\n",
        "# o loop simples é mais garantido de não estourar a memória.\n",
        "\n",
        "imagens = sorted([\n",
        "    f for f in os.listdir(path)\n",
        "    if f.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif'))\n",
        "])\n",
        "\n",
        "registros = []\n",
        "\n",
        "print(f\"Iniciando processamento de alta precisão em {len(imagens)} imagens...\")\n",
        "\n",
        "for nome in tqdm(imagens):\n",
        "    caminho = os.path.join(path, nome)\n",
        "    try:\n",
        "        dados = processar_folha(caminho, nome)\n",
        "        if dados:\n",
        "            registros.append(dados)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar {nome}: {e}\")"
      ],
      "metadata": {
        "id": "W0VvyztWams6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criação e Salvamento dos Descritores"
      ],
      "metadata": {
        "id": "JXXWViJga7LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(registros)\n",
        "\n",
        "print(\"\\nProcessamento Concluído.\")\n",
        "print(df.head())\n",
        "\n",
        "# Salvar CSV\n",
        "df.to_csv(\"descritores_folhas.csv\", index=False, sep=';')"
      ],
      "metadata": {
        "id": "ST2oeXvOa9Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redução de Dimensionalidade (PCA)"
      ],
      "metadata": {
        "id": "BQRp9gJlaDM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leitura do CSV"
      ],
      "metadata": {
        "id": "L4rPtR2taLA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "metadata": {
        "id": "AGLLQ9XbaJk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o CSV gerado anteriormente\n",
        "df = pd.read_csv(\"descritores_folhas.csv\", sep=';')\n",
        "\n",
        "print(\"Formato do DataFrame:\", df.shape)\n",
        "display(df.head())\n"
      ],
      "metadata": {
        "id": "lYzbfjmEaQkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalização dos Descritores"
      ],
      "metadata": {
        "id": "P_C2MwpZabXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionar SOMENTE os descritores numéricos\n",
        "X = df[[\n",
        "    \"Circularidade\",\n",
        "    \"Excentricidade\",\n",
        "    \"Num_Cantos\",\n",
        "    \"Razao_Altura_Largura\"\n",
        "]].values\n",
        "\n",
        "# Normalização (z-score)\n",
        "scaler = StandardScaler()\n",
        "X_norm = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Média após normalização:\", X_norm.mean(axis=0))\n",
        "print(\"Desvio padrão após normalização:\", X_norm.std(axis=0))\n"
      ],
      "metadata": {
        "id": "v-tcGz58alm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicação PCA"
      ],
      "metadata": {
        "id": "npSGpBmYbucf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_norm)\n",
        "\n",
        "# Variância explicada\n",
        "var_exp = pca.explained_variance_ratio_\n",
        "var_exp_acumulada = np.cumsum(var_exp)\n",
        "\n",
        "for i, v in enumerate(var_exp_acumulada):\n",
        "    print(f\"Componente {i+1}: Variância acumulada = {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "RkQL3s9Ibv5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Justificativa"
      ],
      "metadata": {
        "id": "lyzURZaRb1MW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As duas primeiras componentes principais explicam aproximadamente 79,8% da variância total, sendo suficientes para análise exploratória e visualização em 2D, enquanto três componentes explicam 92,8% da variância, podendo ser utilizadas quando se deseja maior fidelidade na representação dos dados."
      ],
      "metadata": {
        "id": "5fLtnqAq2naz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(var_exp_acumulada)+1),\n",
        "         var_exp_acumulada,\n",
        "         marker='o')\n",
        "\n",
        "plt.xlabel(\"Número de Componentes\")\n",
        "plt.ylabel(\"Variância Explicada Acumulada\")\n",
        "plt.title(\"Análise da Variância Explicada (PCA)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "paJmD7LXb2WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA 2 Componentes"
      ],
      "metadata": {
        "id": "7AzI50AdcgH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escolha livre dos componentes (começa em 1 para ficar intuitivo)\n",
        "comp_x = 1   # PC1\n",
        "comp_y = 2   # PC2\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(\n",
        "    X_pca[:, comp_x-1],\n",
        "    X_pca[:, comp_y-1],\n",
        "    s=25\n",
        ")\n",
        "\n",
        "plt.xlabel(f\"PC{comp_x}\")\n",
        "plt.ylabel(f\"PC{comp_y}\")\n",
        "plt.title(f\"PCA: PC{comp_x} × PC{comp_y}\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uHTkQdG_ciiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classificação"
      ],
      "metadata": {
        "id": "nqX4F5g17fBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Importações de Machine Learning\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "rMIUh-fy8Fas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparação dos Dados"
      ],
      "metadata": {
        "id": "w4AGNKFgDgbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURAÇÃO ---\n",
        "path = \"/root/.cache/kagglehub/datasets/gauravneupane/flavia-dataset/versions/1/Leaves\"\n",
        "\n",
        "# --- 1. Mapeamento das Classes Flavia ---\n",
        "flavia_intervals = {\n",
        "    1: (1001, 1059),  2: (1060, 1122),  3: (1123, 1194),  4: (1195, 1267),\n",
        "    5: (1268, 1323),  6: (1324, 1385),  7: (1386, 1437),  8: (1438, 1496),\n",
        "    9: (1497, 1551), 10: (1552, 1616), 11: (2001, 2050), 12: (2051, 2113),\n",
        "    13: (2114, 2165), 14: (2166, 2230), 15: (2231, 2290), 16: (2291, 2346),\n",
        "    17: (2347, 2423), 18: (2424, 2485), 19: (2486, 2546), 20: (2547, 2612),\n",
        "    21: (2616, 2675), 22: (3001, 3055), 23: (3056, 3110), 24: (3111, 3175),\n",
        "    25: (3176, 3229), 26: (3230, 3281), 27: (3282, 3334), 28: (3335, 3389),\n",
        "    29: (3390, 3446), 30: (3447, 3510), 31: (3511, 3563), 32: (3566, 3621)\n",
        "}\n",
        "\n",
        "def obter_classe_flavia(nome_imagem):\n",
        "    try:\n",
        "        # Remove a extensão e converte para inteiro\n",
        "        numero = int(nome_imagem.split('.')[0])\n",
        "\n",
        "        # Verifica em qual intervalo o número se encaixa\n",
        "        for classe_id, (inicio, fim) in flavia_intervals.items():\n",
        "            if inicio <= numero <= fim:\n",
        "                return classe_id\n",
        "\n",
        "        return -1 # Não encontrado / Outro padrão\n",
        "    except:\n",
        "        return -1\n",
        "\n",
        "# Aplica a correção\n",
        "df['Classe'] = df['Imagem'].apply(obter_classe_flavia)\n",
        "\n",
        "# Removemos imagens que porventura não estejam nos intervalos (-1)\n",
        "df_limpo = df[df['Classe'] != -1].copy()\n",
        "\n",
        "# Atualiza X e y com o dataframe limpo\n",
        "colunas_numericas = [\"Circularidade\", \"Excentricidade\", \"Num_Cantos\", \"Razao_Altura_Largura\"]\n",
        "X = df_limpo[colunas_numericas].values\n",
        "y = df_limpo['Classe'].values\n",
        "\n",
        "# --- 2. Estatísticas e Visualização Corrigida ---\n",
        "contagem_classes = df_limpo['Classe'].value_counts().sort_index()\n",
        "classes_unicas = sorted(df_limpo['Classe'].unique())\n",
        "\n",
        "print(\"=\"*40)\n",
        "print(\"ESTATÍSTICAS CORRIGIDAS (REAL FLAVIA)\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Total de Imagens Válidas: {len(df_limpo)}\")\n",
        "print(f\"Total de Classes: {len(classes_unicas)}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Classe':<10} | {'Qtd Imagens':<15}\")\n",
        "print(\"-\" * 40)\n",
        "# Mostra apenas as 10 primeiras para não poluir, ou tire o [:10] para ver tudo\n",
        "for classe in classes_unicas[:10]:\n",
        "    print(f\"{str(classe):<10} | {contagem_classes[classe]:<15}\")\n",
        "print(\"... (restante das classes omitido)\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# --- 3. Plotagem das Amostras ---\n",
        "n_classes = len(classes_unicas)\n",
        "cols = 5\n",
        "rows = math.ceil(n_classes / cols)\n",
        "\n",
        "plt.figure(figsize=(15, 3.5 * rows))\n",
        "plt.suptitle(\"Amostra Real: Uma folha de cada espécie Flavia\", fontsize=16, y=1.01)\n",
        "\n",
        "for i, classe in enumerate(classes_unicas):\n",
        "    # Pega a primeira imagem desta classe\n",
        "    amostra = df_limpo[df_limpo['Classe'] == classe].iloc[0]\n",
        "    nome_img = amostra['Imagem']\n",
        "    caminho_completo = os.path.join(path, nome_img)\n",
        "\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "\n",
        "    try:\n",
        "        img = cv2.imread(caminho_completo)\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"Classe {classe}\\n({nome_img})\", fontsize=10, backgroundcolor='#eeeeee')\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, \"Img missing\", ha='center')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O7oIJXO1DD4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificador K-NN e Curva de Desempenho"
      ],
      "metadata": {
        "id": "WRtiNVfwDjbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Classificador k-NN (Curva de Desempenho) ---\n",
        "\n",
        "print(\"\\n--- A iniciar testes com k-NN ---\")\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "k_range = range(1, 21)\n",
        "k_scores = []\n",
        "\n",
        "for k in k_range:\n",
        "    # Pipeline: Normaliza -> Classifica\n",
        "    # É importante normalizar DENTRO do loop para evitar data leakage na validação cruzada\n",
        "    knn = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=k))\n",
        "\n",
        "    # Executa validação cruzada e guarda a média das acurácias\n",
        "    scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "    k_scores.append(scores.mean())\n",
        "\n",
        "# Gráfico Desempenho x k\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, k_scores, marker='o', linestyle='-', color='b')\n",
        "plt.title('Desempenho k-NN: Acurácia vs Valor de k')\n",
        "plt.xlabel('Valor de k (Vizinhos)')\n",
        "plt.ylabel('Acurácia Média (Cross-Validation)')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "melhor_k = k_range[np.argmax(k_scores)]\n",
        "print(f\"Melhor k encontrado: {melhor_k} com acurácia de {max(k_scores):.4f}\")"
      ],
      "metadata": {
        "id": "aMOoqjLpDIIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificador SVM"
      ],
      "metadata": {
        "id": "39W1iF0YDpPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Classificador SVM (Comparação de Kernels) ---\n",
        "\n",
        "print(\"\\n--- A iniciar testes com SVM ---\")\n",
        "\n",
        "kernels = ['linear', 'rbf']\n",
        "svm_results = {}\n",
        "\n",
        "for kernel in kernels:\n",
        "    # Pipeline: Normaliza -> SVM\n",
        "    svm = make_pipeline(StandardScaler(), SVC(kernel=kernel, random_state=42))\n",
        "\n",
        "    scores = cross_val_score(svm, X, y, cv=cv, scoring='accuracy')\n",
        "    svm_results[kernel] = scores.mean()\n",
        "    print(f\"Kernel '{kernel}': Acurácia média = {scores.mean():.4f}\")\n",
        "\n",
        "# Gráfico comparativo SVM\n",
        "plt.figure(figsize=(6, 5))\n",
        "barras = plt.bar(svm_results.keys(), svm_results.values(), color=['skyblue', 'salmon'])\n",
        "plt.ylim(0, 1.1)\n",
        "plt.ylabel('Acurácia Média')\n",
        "plt.title('Comparação de Kernels SVM')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar in barras:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f\"{yval:.2f}\", ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Erm1dUrTDOsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação do Sistema"
      ],
      "metadata": {
        "id": "gvjYehrtD3iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisão Treino e Teste"
      ],
      "metadata": {
        "id": "ZAhXrMruGtzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# 1. Divisão Treino e Teste\n",
        "# Reservamos 30% dos dados para teste final (dados que o modelo nunca viu)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "UNCztixBGXCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento do Modelo Escolhido"
      ],
      "metadata": {
        "id": "LbTlG_3iGwam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Treinamento do Modelo Escolhido\n",
        "# Usaremos o SVM com kernel RBF (geralmente o melhor para este caso)\n",
        "# Se o seu k-NN foi muito melhor, troque SVC por KNeighborsClassifier\n",
        "model = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1.0, gamma='scale'))\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VYdHNn02GbK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predição"
      ],
      "metadata": {
        "id": "fW-Tr6XMGzh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Predição\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "bhZad2RvGmTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Métricas Numéricas (Precisão, Recall, F1, Acurácia)"
      ],
      "metadata": {
        "id": "zAT88zCaG06f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- A) Métricas Numéricas (Precisão, Recall, F1, Acurácia) ---\n",
        "print(\"=\"*60)\n",
        "print(\"RELATÓRIO DE CLASSIFICAÇÃO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# O output_dict=False gera o texto formatado.\n",
        "# O zero_division=0 evita erros se alguma classe não for predita.\n",
        "report = classification_report(y_test, y_pred, zero_division=0)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(report)\n",
        "print(f\"\\nACURÁCIA GLOBAL: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "7Hij73YNGqKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matriz de Confusão Visual"
      ],
      "metadata": {
        "id": "8h8xR4m1G6K2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- B) Matriz de Confusão Visual ---\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(12, 10)) # Tamanho grande para ver todas as classes\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.unique(y),\n",
        "            yticklabels=np.unique(y))\n",
        "\n",
        "plt.title('Matriz de Confusão (SVM RBF)')\n",
        "plt.ylabel('Classe Real (Verdade)')\n",
        "plt.xlabel('Classe Predita (Modelo)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IR4yYZApGsDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussão para o Relatório"
      ],
      "metadata": {
        "id": "wSddSsNUMha3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os principais erros ocorrem entre espécies que possuem razões de aspecto e circularidades similares (ex: folhas lanceoladas de diferentes famílias). O número de cantos ajudou a diferenciar folhas lisas de folhas serrilhadas, mas a similaridade geométrica pura é um limitador para modelos que não utilizam textura ou cor.\n"
      ],
      "metadata": {
        "id": "CbrNYwb5YqNm"
      }
    }
  ]
}